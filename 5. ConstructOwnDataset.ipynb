{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f99b1ce3-bc8a-4bf0-8a4d-9826a2212b19",
   "metadata": {},
   "source": [
    "# Construct and simplify our own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb122c1e-d307-44f1-8ea6-5d980fc91d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "import SimpleITK as sitk\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from lib.folder import FolderMg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a9ad3d-d41a-4a3f-85bd-5bee818a40b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDuplicateFileName(file_list: List[Path]):\n",
    "    file_names = []\n",
    "    for f in file_list:\n",
    "        f_name = f.name.split(\".\")[0]\n",
    "        if f_name in file_names:\n",
    "            print(f)\n",
    "        else:\n",
    "            file_names.append(f_name)\n",
    "    print(f\"Files should have {len(file_list)}, names have {len(file_names)}\")\n",
    "    return file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "727e4512-c164-4041-8b6f-5490d9e9d9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Folder 'ReviewData' contains 14 folders, which are:\n",
      "  - DataPack1\n",
      "  - DataPack2\n",
      "  - DataPack3\n",
      "  - DataPack4\n",
      "  - DataPack5\n",
      "  - ...\n",
      "\n",
      "Current Folder 'ReviewData' contains NO files\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sourceDataPath = Path(\n",
    "    \"D:\\Medical Image - Research\\Clinical Data Prostate Segmentation Image Packages\\ReviewData\"\n",
    ")\n",
    "sourceDataMg = FolderMg(sourceDataPath)\n",
    "sourceDataMg.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855931ae-6d58-4b65-a6b5-5d56e47595e7",
   "metadata": {},
   "source": [
    "## Get valid Data\n",
    "1. according to the segmentation result, remove file with & in the name.\n",
    "2. find the original file according to valid segmentation result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "305c096f-19a7-4603-9150-9b68cd41f581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataPack1\n",
      "DataPack2\n",
      "DataPack3\n",
      "DataPack4\n",
      "DataPack5\n",
      "DataPack6\n",
      "DataPack7\n",
      "DataPack8\n",
      "DataPack9\n",
      "DataPack10\n",
      "DataPack11\n",
      "DataPack12\n",
      "DataPack13\n",
      "DataPack14\n"
     ]
    }
   ],
   "source": [
    "validSegmentationFiles = []\n",
    "validOriginalFiles = []\n",
    "for d in sourceDataMg.dirs:\n",
    "    print(d.name)\n",
    "    tempOgMg = FolderMg(d)\n",
    "    # tempOgMg.ls()\n",
    "    tempSegMg = FolderMg(d.joinpath(\"Segmentation\"))\n",
    "    # tempSegMg.ls()\n",
    "\n",
    "    useableFile = [f for f in tempSegMg.files if \"&\" not in f.name]\n",
    "    for i, segf in enumerate(useableFile):\n",
    "        segf_name = segf.name.split(\".\")[0]\n",
    "        matchOgFiles = []\n",
    "        for ogf in tempOgMg.files:\n",
    "            ogf_name = ogf.stem\n",
    "            if segf_name == ogf_name:\n",
    "                matchOgFiles.append(ogf)\n",
    "        # matchOgFiles = [ ogf for ogf in tempOgMg.files if segf_name in ogf.name and ogf.name in segf_name]\n",
    "        if len(matchOgFiles) != 1:\n",
    "            print(segf, matchOgFiles)\n",
    "            break\n",
    "        validOriginalFiles.extend(matchOgFiles)\n",
    "    validSegmentationFiles.extend(useableFile)\n",
    "assert len(validOriginalFiles) == len(validSegmentationFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c3e07d-a220-410a-bf05-46bab20cd13b",
   "metadata": {},
   "source": [
    "## Filter out the same size original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f1326e1-2904-44b2-bfb7-7241e213c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeDict = {}\n",
    "for i, f in enumerate(validOriginalFiles):\n",
    "    key = f.stat().st_size\n",
    "    if key in sizeDict:\n",
    "        duplicatesFiles = sourceDataPath.parent.joinpath(\"dup\", sizeDict[key].stem)\n",
    "        if not duplicatesFiles.exists():\n",
    "            Path.mkdir(duplicatesFiles, parents=True)\n",
    "        shutil.copy2(f, duplicatesFiles)\n",
    "        shutil.copy2(sizeDict[key], duplicatesFiles)\n",
    "        # print(key, sizeDict[key], f)\n",
    "    else:\n",
    "        sizeDict[key] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9da436a-c4ef-43cc-906f-724b82073cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sizeDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb049baf-6010-4a8e-87fa-d67c547f3177",
   "metadata": {},
   "source": [
    "## Shuffle the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f927e5a-e9eb-4db5-b6aa-0b7803dce605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Medical Image - Research\\Clinical Data Prostate Segmentation Image Packages\\ReviewData\\DataPack1\\FollowMR_t2_tse_fdixon_tra_p2_256_in_RD_UT20211224151916.mha\n",
      "D:\\Medical Image - Research\\Clinical Data Prostate Segmentation Image Packages\\ReviewData\\DataPack8\\MainMR_t2_tse_fdixon_tra_p2_256_W_RD_UT20211224151916.mha\n",
      "99\n",
      "Files should have 99, names have 99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'MainMR_t2_tse_fdixon_tra_p2_256_W_RD_UT20211224151916'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ogFiles = list(sizeDict.values())\n",
    "random.shuffle(ogFiles)\n",
    "print(list(sizeDict.values())[0])\n",
    "print(ogFiles[0])\n",
    "print(len(ogFiles))\n",
    "ogFilesNames = findDuplicateFileName(ogFiles)\n",
    "ogFilesNames[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82434a74-e018-4c0e-8472-be5ddfafccf8",
   "metadata": {},
   "source": [
    "## Find its corrsponding segmentation result given new original data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7050ec2f-2478-42bf-b01a-222b6d40ff51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ogSegPair = {}\n",
    "for ogf in ogFiles:\n",
    "    ogf_name = ogf.name.split(\".\")[0]\n",
    "    matchFiles = []\n",
    "    for segf in validSegmentationFiles:\n",
    "        segf_name = segf.name.split(\".\")[0]\n",
    "        if ogf_name == segf_name:\n",
    "            matchFiles.append(segf)\n",
    "            # print(ogf_name, segf_name)\n",
    "    if len(matchFiles) != 1:\n",
    "        print(ogf, matchFiles)\n",
    "        break\n",
    "    ogSegPair[ogf_name] = [ogf, matchFiles[0]]\n",
    "len(ogSegPair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337d33d1-4ef5-4610-8abf-c1965919d64c",
   "metadata": {},
   "source": [
    "## Construct Dataset and save to folder\n",
    "convert .mha and .nrrd to nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26d60d85-d8a4-4fa7-94cb-5cf3564ce9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is done\n"
     ]
    }
   ],
   "source": [
    "datasetPath = sourceDataPath.parent.joinpath(f\"Dataset078_UltrastProstate\")\n",
    "if not datasetPath.exists():\n",
    "    datasetPath.mkdir(parents=True)\n",
    "segmentationPath = datasetPath.joinpath(\"labels\")\n",
    "if not datasetPath.exists():\n",
    "    datasetPath.mkdir(parents=True)\n",
    "if not segmentationPath.exists():\n",
    "    segmentationPath.mkdir(parents=True)\n",
    "\n",
    "for k, v in ogSegPair.items():\n",
    "    ogf, segf = v[0], v[1]\n",
    "    ogf_name = ogf.name.split(\".\")[0]\n",
    "    segf_name = segf.name.split(\".\")[0]\n",
    "    if ogf_name != segf_name:\n",
    "        print(ogf_name, segf_name)\n",
    "        break\n",
    "    \n",
    "    # shutil.copy2(ogf, datasetPath)    \n",
    "    shutil.copy2(segf, segmentationPath)\n",
    "    outFileName = datasetPath.joinpath(f\"{ogf.stem}.nii.gz\")\n",
    "    img = sitk.ReadImage(ogf)\n",
    "    sitk.WriteImage(img, fileName=outFileName)\n",
    "print(\"Dataset is done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41e6754-d564-4055-9ebb-3b14d453be51",
   "metadata": {},
   "source": [
    "## Convert Dataset to nnUNet structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4beca277-6a66-45a3-a112-6182e8d98ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 79\n"
     ]
    }
   ],
   "source": [
    "trainRatio = 0.8\n",
    "nnUNetDatasetPath = datasetPath.parent.joinpath(datasetPath.name + f\"{trainRatio}\")\n",
    "imageTrFolder = nnUNetDatasetPath.joinpath(\"imagesTr\")\n",
    "imageTsFolder = nnUNetDatasetPath.joinpath(\"imagesTs\")\n",
    "labelTrFolder = nnUNetDatasetPath.joinpath(\"labelsTr\")\n",
    "labelTsFolder = nnUNetDatasetPath.joinpath(\"labelsTs\")\n",
    "if not nnUNetDatasetPath.exists():\n",
    "    nnUNetDatasetPath.mkdir(parents=True)\n",
    "    imageTrFolder.mkdir(parents=True)\n",
    "    imageTsFolder.mkdir(parents=True)\n",
    "    labelTrFolder.mkdir(parents=True)\n",
    "    labelTsFolder.mkdir(parents=True)\n",
    "    \n",
    "datasetFolderMg = FolderMg(datasetPath)\n",
    "segmentationMg = FolderMg(segmentationPath)\n",
    "\n",
    "nFile = datasetFolderMg.nFile\n",
    "nTrain = int(nFile * 0.8)\n",
    "for i, (ogf, segf) in enumerate(zip(datasetFolderMg.files, segmentationMg.files)):\n",
    "    ogf_name = ogf.name.split(\".\")[0]\n",
    "    segf_name = segf.name.split(\".\")[0]\n",
    "    assert ogf_name == segf_name\n",
    "    new_ogf_stem = f\"Ultrast_{str(i).zfill(3)}_0000\"\n",
    "    new_segf_stem = f\"Ultrast_{str(i).zfill(3)}\"\n",
    "    ogf_extension = \"\".join(ogf.suffixes)\n",
    "    segf_extension = \"\".join(segf.suffixes)\n",
    "    # print(new_ogf_stem, new_segf_stem, ogf_extension, segf_extension, new_ogf, new_segf)\n",
    "    if i < nTrain:\n",
    "        new_ogf = imageTrFolder.joinpath(new_ogf_stem + ogf_extension)\n",
    "        new_segf = labelTrFolder.joinpath(new_segf_stem + segf_extension)\n",
    "        shutil.copy2(ogf, new_ogf)\n",
    "        shutil.copy2(segf, new_segf)\n",
    "    else:\n",
    "        new_ogf = imageTsFolder.joinpath(new_ogf_stem + ogf_extension)\n",
    "        new_segf = labelTsFolder.joinpath(new_segf_stem + segf_extension)\n",
    "        shutil.copy2(ogf, new_ogf)\n",
    "        shutil.copy2(segf, new_segf)\n",
    "\n",
    "print(nFile, nTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2b980d-d8f4-4abd-a2fe-6d0ee08ca4bf",
   "metadata": {},
   "source": [
    "## Generate dataset.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff200f9f-8908-46da-a28a-e751b654e2a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nnunetv2.dataset_conversion.generate_dataset_json import generate_dataset_json\n",
    "\n",
    "channel_names = { 0: \"T2\"}\n",
    "labels = {'background':0, 'prostate':1}\n",
    "num_training_cases = 79\n",
    "file_ending = \".nii.gz\"\n",
    "overwrite_image_reader_writer = \"SimpleITKIO\"\n",
    "generate_dataset_json(str(nnUNetDatasetPath), channel_names=channel_names, labels=labels,num_training_cases=num_training_cases,file_ending=file_ending,overwrite_image_reader_writer=overwrite_image_reader_writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
